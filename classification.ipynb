{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPw+pS8IpbVkZhbfvQErCXw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anil2k/Image-classification-from-scratch-keras-/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ignku_GRxqyK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhFVrBstzC4I",
        "outputId": "9b444e55-6422-48ef-dd9f-2b8ad97199f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtVFGq8F2XMA",
        "outputId": "baed8ec6-3314-4ee0-fde3-40741b78ec06"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(256, 256,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        " # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='CategoricalCrossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#for two class activation: sigmoid Dence:1 loss: BinaryCrossentropy\n",
        "#for more than two: softmax Dence : no of classes loss: CategoricalCrossentropy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 254, 254, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 125, 125, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 60, 60, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 60, 60, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                3686464   \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 260       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 3,715,364\n",
            "Trainable params: 3,715,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy5z617V6aho",
        "outputId": "14dcfa5d-10d0-46f1-96da-49d4dd97e417"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "batch_size = 16\n",
        "img_height=256\n",
        "img_width=256\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2) # set validation split\n",
        "train_data_dir='/content/drive/MyDrive/assignment/Busigence_Technologies/Input/Dataset/train'\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "print(train_generator.class_indices)\n",
        "print(train_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 354 images belonging to 4 classes.\n",
            "Found 86 images belonging to 4 classes.\n",
            "{'category_1': 0, 'category_2': 1, 'category_3': 2, 'category_4': 3}\n",
            "{'category_1': 0, 'category_2': 1, 'category_3': 2, 'category_4': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz9DiIHA3F_-",
        "outputId": "0559c735-c122-4fd9-e712-24199aa3d102"
      },
      "source": [
        "nb_epochs=20\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs)\n",
        "model.save('/content/drive/MyDrive/assignment/Busigence_Technologies/Output/first_try.h5')  # always save your weights after training or during training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "22/22 [==============================] - 9s 420ms/step - loss: 0.0789 - accuracy: 0.9659 - val_loss: 0.6874 - val_accuracy: 0.8250\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 9s 405ms/step - loss: 0.0656 - accuracy: 0.9734 - val_loss: 0.5081 - val_accuracy: 0.8625\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 9s 404ms/step - loss: 0.0739 - accuracy: 0.9793 - val_loss: 0.5536 - val_accuracy: 0.8500\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 9s 411ms/step - loss: 0.0539 - accuracy: 0.9793 - val_loss: 0.6548 - val_accuracy: 0.8500\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 9s 403ms/step - loss: 0.1007 - accuracy: 0.9763 - val_loss: 0.4355 - val_accuracy: 0.8375\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 9s 400ms/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.6536 - val_accuracy: 0.8250\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 9s 404ms/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.6142 - val_accuracy: 0.8250\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 9s 407ms/step - loss: 0.0668 - accuracy: 0.9822 - val_loss: 0.7997 - val_accuracy: 0.8375\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 9s 401ms/step - loss: 0.0434 - accuracy: 0.9822 - val_loss: 0.5316 - val_accuracy: 0.8750\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 9s 404ms/step - loss: 0.0674 - accuracy: 0.9793 - val_loss: 0.7573 - val_accuracy: 0.8500\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 9s 411ms/step - loss: 0.0612 - accuracy: 0.9852 - val_loss: 0.6972 - val_accuracy: 0.8875\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 9s 406ms/step - loss: 0.0609 - accuracy: 0.9734 - val_loss: 0.5814 - val_accuracy: 0.8625\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 9s 399ms/step - loss: 0.0817 - accuracy: 0.9793 - val_loss: 0.6595 - val_accuracy: 0.8750\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 9s 404ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.6378 - val_accuracy: 0.8250\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 9s 403ms/step - loss: 0.0437 - accuracy: 0.9852 - val_loss: 0.8687 - val_accuracy: 0.8250\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 9s 401ms/step - loss: 0.0835 - accuracy: 0.9793 - val_loss: 0.6798 - val_accuracy: 0.8250\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 9s 402ms/step - loss: 0.0385 - accuracy: 0.9911 - val_loss: 0.7529 - val_accuracy: 0.8375\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 9s 402ms/step - loss: 0.0315 - accuracy: 0.9941 - val_loss: 0.6669 - val_accuracy: 0.8500\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 9s 397ms/step - loss: 0.0135 - accuracy: 0.9941 - val_loss: 0.4057 - val_accuracy: 0.8875\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 9s 406ms/step - loss: 0.0623 - accuracy: 0.9734 - val_loss: 1.0597 - val_accuracy: 0.8500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkjlgTqKHhii",
        "outputId": "b8459c35-5304-4423-92bc-b6a240a62656"
      },
      "source": [
        "from keras.models import load_model\n",
        "model1 = load_model('/content/drive/MyDrive/assignment/Busigence_Technologies/Output/first_try.h5')\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 254, 254, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 125, 125, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 60, 60, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 60, 60, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                3686464   \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 260       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 3,715,364\n",
            "Trainable params: 3,715,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouZnXAGuGiVA",
        "outputId": "7b8f6caa-a553-4414-976d-98bdb21b6cc3"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "test_img = []\n",
        "for img in glob.glob(\"/content/drive/MyDrive/assignment/Busigence_Technologies/Input/Dataset/test/*.png\"):\n",
        "    #n= cv2.imread(img)\n",
        "    test_img.append(img)\n",
        "print(len(test_img))\n",
        "print(test_img[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "/content/drive/MyDrive/assignment/Busigence_Technologies/Input/Dataset/test/4051.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osA1qq1oKZwW",
        "outputId": "000241a6-5691-4ec0-e6c4-4f23195a3e28"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "image_size = (256, 256)\n",
        "result=[]\n",
        "for a in test_img:\n",
        "  img = keras.preprocessing.image.load_img(\n",
        "    a, target_size=image_size\n",
        "    )\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\n",
        "  #img_array.shape\n",
        "  img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "  #print(img_array.shape)\n",
        "  predictions = model1.predict(img_array)\n",
        "  print(predictions)\n",
        "\n",
        "  if int((predictions[0][0]))==1:\n",
        "    pred='category_1'\n",
        "  if int(predictions[0][1])==1:\n",
        "    pred='category_2'\n",
        "  if int(predictions[0][2])==1:\n",
        "    pred='category_3'\n",
        "  if int(predictions[0][3])==1:\n",
        "    pred='category_4'\n",
        "  pred_row=[a[76:],pred]\n",
        "  result.append(pred_row)\n",
        "#{'category_1': 0, 'category_2': 1, 'category_3': 2, 'category_4': 3}\n",
        "\n",
        "score = predictions[0]\n",
        "print(predictions[0][1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 0. 0. 1.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "[[1. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1.]]\n",
            "[[1. 0. 0. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[1. 0. 0. 0.]]\n",
            "[[1. 0. 0. 0.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "[[0. 0. 0. 1.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "[[1. 0. 0. 0.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 0. 0. 1.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "[[0. 0. 1. 0.]]\n",
            "[[0. 0. 0. 1.]]\n",
            "[[0. 1. 0. 0.]]\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJkZGYDwS3fC",
        "outputId": "9cc8826b-6472-4b8a-fbf2-ae33ea834f64"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['4052.png', 'category_3'],\n",
              " ['4051.png', 'category_3'],\n",
              " ['6052.png', 'category_2'],\n",
              " ['4050.png', 'category_3'],\n",
              " ['C053.png', 'category_4'],\n",
              " ['6053.png', 'category_2'],\n",
              " ['1052.png', 'category_1'],\n",
              " ['C052.png', 'category_4'],\n",
              " ['1051.png', 'category_1'],\n",
              " ['4043.png', 'category_3'],\n",
              " ['Test_original_4052.png_31cd9a66-9edc-4445-b4bc-9b0239b342e0.png',\n",
              "  'category_3'],\n",
              " ['Test_original_4052.png_78b7cca7-2a16-4f3c-829d-e4937b5f2dc2.png',\n",
              "  'category_3'],\n",
              " ['Test_original_1052.png_b95bc311-bae0-48a7-8b9f-d0eddf1ddf2b.png',\n",
              "  'category_1'],\n",
              " ['Test_original_1052.png_22a82512-5b1f-4072-a4af-9a8af40653f0.png',\n",
              "  'category_1'],\n",
              " ['Test_original_6052.png_9950e35a-38c7-4388-b391-ce50bb8ea1a7.png',\n",
              "  'category_2'],\n",
              " ['Test_original_4043.png_fffcbc29-3aff-40c0-bdf9-2c12fa6df60b.png',\n",
              "  'category_3'],\n",
              " ['Test_original_6052.png_51c87ecf-ede6-4152-960f-4d56ff913d53.png',\n",
              "  'category_2'],\n",
              " ['Test_original_C052.png_5c226e55-09ba-4fd0-bf6b-e0d2b411baa3.png',\n",
              "  'category_4'],\n",
              " ['Test_original_6053.png_62171105-bdaa-4eb5-b5e7-9b0fb7914715.png',\n",
              "  'category_2'],\n",
              " ['Test_original_1051.png_271f7fb1-f0ab-4ca7-9dae-a352fd0ed8b9.png',\n",
              "  'category_1'],\n",
              " ['Test_original_6053.png_16f2063e-9590-4ae5-b7f9-7f23c8cfa654.png',\n",
              "  'category_2'],\n",
              " ['Test_original_4043.png_615f9058-5c5c-4430-9f11-debd66f8a19a.png',\n",
              "  'category_3'],\n",
              " ['Test_original_C053.png_e7d20702-793e-4207-b174-a8042c05ac3d.png',\n",
              "  'category_4'],\n",
              " ['Test_original_6053.png_c34c8352-0830-4853-81ce-3ea5ecf82313.png',\n",
              "  'category_2'],\n",
              " ['Test_original_4051.png_b90a2ba4-87c6-41e6-ad67-0e0d2e83478c.png',\n",
              "  'category_3'],\n",
              " ['Test_original_4052.png_209d62b3-92ce-4e4d-8006-cf63a40088a4.png',\n",
              "  'category_3'],\n",
              " ['Test_original_6052.png_25bb57e2-b542-47c3-9abb-a1f7c7179ee6.png',\n",
              "  'category_2'],\n",
              " ['Test_original_4052.png_a2ba34f8-9e8b-4b2d-ad89-612c261a9654.png',\n",
              "  'category_3'],\n",
              " ['Test_original_C053.png_84d8e7c9-490f-4579-b9a9-501a8ca02cfe.png',\n",
              "  'category_4'],\n",
              " ['Test_original_6053.png_445dbbe1-4b09-4d56-aede-ab1695664ead.png',\n",
              "  'category_2']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fOiWf_UMvqF"
      },
      "source": [
        "import csv \n",
        "    \n",
        "# field names \n",
        "fields = ['imageid','predicted_label'] \n",
        "    \n",
        "\n",
        "# name of csv file \n",
        "filename = \"/content/drive/MyDrive/assignment/Busigence_Technologies/Output/results1.csv\"\n",
        "    \n",
        "# writing to csv file \n",
        "with open(filename, 'w') as csvfile: \n",
        "    # creating a csv writer object \n",
        "    csvwriter = csv.writer(csvfile) \n",
        "        \n",
        "    # writing the fields \n",
        "    csvwriter.writerow(fields) \n",
        "        \n",
        "    # writing the data rows \n",
        "    csvwriter.writerows(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}